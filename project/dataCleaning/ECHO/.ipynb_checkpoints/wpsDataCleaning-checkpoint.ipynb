{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d8a0967-1c59-46c9-b341-685ceffffce2",
   "metadata": {},
   "source": [
    "# EPA ECHO WPS Enforcement Dataset\n",
    "\n",
    "## Data Overview\n",
    "This dataset contains state-level enforcement data related to the Worker Protection Standard (WPS) reported by the EPA for agricultural pesticide use. It spans multiple years (2011–2021) and includes data on inspections, violations, and enforcement actions across U.S. states and territories. The dataset differentiates between activities carried out by state agencies, tribal authorities, and the EPA itself.\n",
    "\n",
    "## Data Structure\n",
    "    state (string): Name of the U.S. state or territory\n",
    "    facilities-comm (float): Number of commercial pesticide-use facilities\n",
    "    facilities-ag (float): Number of agricultural pesticide-use facilities\n",
    "    workers-comm (float): Number of workers in commercial pesticide-use facilities\n",
    "    workers-ag (float): Number of workers in agricultural pesticide-use facilities\n",
    "\n",
    "The following groups of columns repeat by year, indicating different enforcement categories:\n",
    "insp-[agency]-[year]: Number of inspections conducted by the specified agency (state, tribe, EPA) in that year\n",
    "viol_retaliation-[agency]-[year]: Number of retaliation-related violations identified by agency and year\n",
    "viol_other-[agency]-[year]: Other types of violations reported\n",
    "enf_civil-[agency]-[year]: Civil enforcement actions initiated\n",
    "enf_criminal-[agency]-[year]: Criminal enforcement actions initiated\n",
    "enf_fines-[agency]-[year]: Fines assessed by each agency\n",
    "enf_stopsale-[agency]-[year]: Stop-sale orders issued\n",
    "\n",
    "Note: The [agency] field may include state, tribe, or epa. Year ranges from 2011 to 2021.\n",
    "\n",
    "Values are generally numerical, but may include missing values (NaN) where data is not available or not reported.\n",
    "\n",
    "## Data Collection & Processing\n",
    "The data was sourced from the EPA's ECHO (Enforcement and Compliance History Online) reports related to pesticide use under the Worker Protection Standard. It has been cleaned for consistency and includes harmonized column naming to support year-over-year comparison. Each column reflects a specific enforcement metric over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce7dede-1e84-4182-a538-81b1631804c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "# Read the raw WPS enforcement dataset\n",
    "df_wps = pd.read_csv(\"wps-data.csv\")\n",
    "\n",
    "# Print the number of rows and preview the structure\n",
    "print(f\"Dataset size: {len(df_wps)} rows\")\n",
    "df_wps.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "057dee12-ba0b-4bcb-a4ed-cefdc5384db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of valid U.S. states to filter data against\n",
    "US_STATES = [\n",
    "    'ALABAMA', 'ALASKA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA', 'COLORADO', 'CONNECTICUT',\n",
    "    'DELAWARE', 'FLORIDA', 'GEORGIA', 'HAWAII', 'IDAHO', 'ILLINOIS', 'INDIANA', 'IOWA',\n",
    "    'KANSAS', 'KENTUCKY', 'LOUISIANA', 'MAINE', 'MARYLAND', 'MASSACHUSETTS', 'MICHIGAN',\n",
    "    'MINNESOTA', 'MISSISSIPPI', 'MISSOURI', 'MONTANA', 'NEBRASKA', 'NEVADA',\n",
    "    'NEW HAMPSHIRE', 'NEW JERSEY', 'NEW MEXICO', 'NEW YORK', 'NORTH CAROLINA',\n",
    "    'NORTH DAKOTA', 'OHIO', 'OKLAHOMA', 'OREGON', 'PENNSYLVANIA', 'RHODE ISLAND',\n",
    "    'SOUTH CAROLINA', 'SOUTH DAKOTA', 'TENNESSEE', 'TEXAS', 'UTAH', 'VERMONT',\n",
    "    'VIRGINIA', 'WASHINGTON', 'WEST VIRGINIA', 'WISCONSIN', 'WYOMING'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a543d209-2035-4660-b39a-ad8c698000c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and clean the WPS dataset\n",
    "def load_and_clean_wps(file_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Standardize state names\n",
    "    df[\"state\"] = df[\"state\"].str.upper().str.strip()\n",
    "    df = df[df[\"state\"].isin(US_STATES)]\n",
    "\n",
    "    # Clean column names (lowercase and underscore formatting)\n",
    "    df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579c9d4e-6a0e-47dc-abd9-2fdc81fa5dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract state-level inspection counts for selected years\n",
    "def extract_inspections(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    insp_cols = [col for col in df.columns if \"insp-state\" in col and (\"2012\" in col or \"2017\" in col)]\n",
    "    df_insp = df[[\"state\"] + insp_cols].copy()\n",
    "\n",
    "    # Reshape to long format\n",
    "    df_insp_long = df_insp.melt(id_vars=[\"state\"], var_name=\"column\", value_name=\"num_inspections\")\n",
    "    df_insp_long[\"year\"] = df_insp_long[\"column\"].str.extract(r'(\\d{4})').astype(int)\n",
    "    df_insp_long.drop(columns=[\"column\"], inplace=True)\n",
    "\n",
    "    return df_insp_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41218e4d-1376-47f0-89c5-d40467c980d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract and sum violations across years\n",
    "def extract_violations(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    viol_cols_2012 = [col for col in df.columns if col.startswith(\"viol_\") and \"2012\" in col]\n",
    "    viol_cols_2017 = [col for col in df.columns if col.startswith(\"viol_\") and \"2017\" in col]\n",
    "\n",
    "    df_viol = df[[\"state\"] + viol_cols_2012 + viol_cols_2017].copy()\n",
    "\n",
    "    # Create total columns\n",
    "    df_viol[\"violations_2012\"] = df_viol[viol_cols_2012].sum(axis=1, skipna=True)\n",
    "    df_viol[\"violations_2017\"] = df_viol[viol_cols_2017].sum(axis=1, skipna=True)\n",
    "\n",
    "    # Reshape into long format\n",
    "    df_2012 = df_viol[[\"state\", \"violations_2012\"]].copy()\n",
    "    df_2012[\"year\"] = 2012\n",
    "    df_2012.rename(columns={\"violations_2012\": \"num_violations\"}, inplace=True)\n",
    "\n",
    "    df_2017 = df_viol[[\"state\", \"violations_2017\"]].copy()\n",
    "    df_2017[\"year\"] = 2017\n",
    "    df_2017.rename(columns={\"violations_2017\": \"num_violations\"}, inplace=True)\n",
    "\n",
    "    return pd.concat([df_2012, df_2017], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6230bd32-5077-49c4-9b9c-dd1ccb4c8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process WPS data\n",
    "input_file = \"wps-data.csv\"  # <- Update path if needed\n",
    "\n",
    "df_wps = load_and_clean_wps(input_file)\n",
    "inspections = extract_inspections(df_wps)\n",
    "violations = extract_violations(df_wps)\n",
    "\n",
    "# Final cleanup and alignment\n",
    "inspections[\"state\"] = inspections[\"state\"].str.upper().str.strip()\n",
    "violations[\"state\"] = violations[\"state\"].str.upper().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff61419b-e9a4-4b0b-90ec-ccc4c0e360c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Merge Status Breakdown ---\n",
      "_merge\n",
      "both          98\n",
      "left_only      0\n",
      "right_only     0\n",
      "Name: count, dtype: int64\n",
      "✅ Final saved file: 'cleaned_inspection_and_violation_data.csv'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>num_inspections</th>\n",
       "      <th>year</th>\n",
       "      <th>num_violations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALASKA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALASKA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  num_inspections  year  num_violations\n",
       "0  ALABAMA            107.0  2012            20.0\n",
       "1  ALABAMA            153.0  2017            12.0\n",
       "2   ALASKA              6.0  2012             6.0\n",
       "3   ALASKA              4.0  2017             4.0\n",
       "4  ARIZONA            116.0  2012             6.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge inspection and violation data by state and year\n",
    "merged_debug = pd.merge(inspections, violations, on=[\"state\", \"year\"], how=\"outer\", indicator=True)\n",
    "\n",
    "# Check merge success\n",
    "print(\"\\n--- Merge Status Breakdown ---\")\n",
    "print(merged_debug[\"_merge\"].value_counts())\n",
    "\n",
    "# Clean final version\n",
    "merged_clean = merged_debug[merged_debug[\"_merge\"] == \"both\"].drop(columns=[\"_merge\"])\n",
    "\n",
    "# Save to CSV\n",
    "merged_clean.to_csv(\"cleaned_inspection_and_violation_data.csv\", index=False)\n",
    "print(\"✅ Final saved file: 'cleaned_inspection_and_violation_data.csv'\")\n",
    "merged_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d3175-2a12-4e2f-81fa-ae6570c8435e",
   "metadata": {},
   "source": [
    "## Data Quality & Limitations\n",
    "Some states and territories have sparse data due to limited reporting or enforcement activity. Tribal and EPA-level enforcement is often reported less consistently than state-level data. Missing values may represent either unreported data or no activity. The dataset does not include detailed case-level incident narratives, focusing instead on aggregate enforcement metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
